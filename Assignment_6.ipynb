{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfJGEa5fJhuR5nHKJhVhHc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesse-venson/Machine-learning/blob/main/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQIW3FzgBusw",
        "outputId": "77c52313-ec04-46c7-a7d2-bbbc50ed0800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TASK 1: GAUSSIAN NAÏVE BAYES CLASSIFIER\n",
            "======================================================================\n",
            "\n",
            "Dataset Shape: (150, 4)\n",
            "Training samples: 105, Test samples: 45\n",
            "Classes: ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "\n",
            "======================================================================\n",
            "(i) STEP-BY-STEP IMPLEMENTATION\n",
            "======================================================================\n",
            "\n",
            "Training Manual Gaussian NB...\n",
            "\n",
            "✓ Model trained successfully!\n",
            "  Prior probabilities: {np.int64(0): np.float64(0.29523809523809524), np.int64(1): np.float64(0.3523809523809524), np.int64(2): np.float64(0.3523809523809524)}\n",
            "\n",
            "✓ Manual Implementation Accuracy: 0.9778 (97.78%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  0 13]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      0.92      0.96        13\n",
            "   virginica       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "\n",
            "======================================================================\n",
            "(ii) BUILT-IN FUNCTION IMPLEMENTATION\n",
            "======================================================================\n",
            "\n",
            "✓ Sklearn Implementation Accuracy: 0.9778 (97.78%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  0 13]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      0.92      0.96        13\n",
            "   virginica       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TASK 2: GRIDSEARCHCV FOR K-NN HYPERPARAMETER TUNING\n",
            "======================================================================\n",
            "\n",
            "Parameter Grid: K values from 1 to 30\n",
            "\n",
            "Performing Grid Search with 5-Fold Cross-Validation...\n",
            "----------------------------------------------------------------------\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "======================================================================\n",
            "GRID SEARCH RESULTS\n",
            "======================================================================\n",
            "\n",
            "✓ Best K value: 1\n",
            "✓ Best Cross-Validation Accuracy: 0.9524 (95.24%)\n",
            "✓ Test Set Accuracy: 1.0000 (100.00%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TOP 5 K VALUES:\n",
            "----------------------------------------------------------------------\n",
            " K  Mean CV Accuracy  Std Dev\n",
            " 1          0.952381 0.030117\n",
            " 7          0.952381 0.030117\n",
            " 8          0.952381 0.030117\n",
            "14          0.952381 0.030117\n",
            " 5          0.942857 0.035635\n",
            "\n",
            "======================================================================\n",
            "CLASSIFICATION REPORT (K-NN with K=1)\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      1.00      1.00        13\n",
            "   virginica       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "\n",
            "1. Gaussian Naïve Bayes:\n",
            "   - Manual Implementation:  97.78%\n",
            "   - Sklearn Implementation: 97.78%\n",
            "\n",
            "2. K-NN with GridSearchCV:\n",
            "   - Best K value: 1\n",
            "   - CV Accuracy: 95.24%\n",
            "   - Test Accuracy: 100.00%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# LAB ASSIGNMENT 6: Gaussian Naïve Bayes & GridSearchCV\n",
        
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TASK 1: GAUSSIAN NAÏVE BAYES CLASSIFIER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nDataset Shape: {X.shape}\")\n",
        "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
        "print(f\"Classes: {iris.target_names}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# (i) STEP-BY-STEP IMPLEMENTATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"(i) STEP-BY-STEP IMPLEMENTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class GaussianNaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the model by calculating priors, means, and variances\"\"\"\n",
        "        self.classes = np.unique(y)\n",
        "        n_samples = len(y)\n",
        "\n",
        "        # Calculate prior probabilities: P(class)\n",
        "        self.priors = {}\n",
        "        for c in self.classes:\n",
        "            self.priors[c] = np.sum(y == c) / n_samples\n",
        "\n",
        "        # Calculate mean and variance for each feature in each class\n",
        "        self.means = {}\n",
        "        self.variances = {}\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X[y == c]  # Get samples of class c\n",
        "            self.means[c] = np.mean(X_c, axis=0)\n",
        "            self.variances[c] = np.var(X_c, axis=0) + 1e-9  # Add small value to avoid division by zero\n",
        "\n",
        "        print(\"\\n✓ Model trained successfully!\")\n",
        "        print(f\"  Prior probabilities: {self.priors}\")\n",
        "\n",
        "    def gaussian_probability(self, x, mean, var):\n",
        "        \"\"\"Calculate Gaussian probability: P(x|class)\"\"\"\n",
        "        coefficient = 1 / np.sqrt(2 * np.pi * var)\n",
        "        exponent = np.exp(-((x - mean) ** 2) / (2 * var))\n",
        "        return coefficient * exponent\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class for each sample\"\"\"\n",
        "        predictions = []\n",
        "\n",
        "        for x in X:\n",
        "            posteriors = []\n",
        "\n",
        "            # Calculate posterior for each class\n",
        "            for c in self.classes:\n",
        "                # Start with prior: P(class)\n",
        "                prior = np.log(self.priors[c])\n",
        "\n",
        "                # Multiply by likelihoods: P(feature|class) for all features\n",
        "                likelihood = np.sum(np.log(self.gaussian_probability(x, self.means[c], self.variances[c])))\n",
        "\n",
        "                # Posterior = prior + likelihood (in log space)\n",
        "                posterior = prior + likelihood\n",
        "                posteriors.append(posterior)\n",
        "\n",
        "            # Choose class with highest posterior\n",
        "            predictions.append(self.classes[np.argmax(posteriors)])\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Train manual implementation\n",
        "print(\"\\nTraining Manual Gaussian NB...\")\n",
        "manual_gnb = GaussianNaiveBayes()\n",
        "manual_gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_manual = manual_gnb.predict(X_test)\n",
        "manual_accuracy = accuracy_score(y_test, y_pred_manual)\n",
        "\n",
        "print(f\"\\n✓ Manual Implementation Accuracy: {manual_accuracy:.4f} ({manual_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_manual = confusion_matrix(y_test, y_pred_manual)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm_manual)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_manual, target_names=iris.target_names))\n",
        "\n",
        "# ============================================================================\n",
        "# (ii) BUILT-IN FUNCTION IMPLEMENTATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"(ii) BUILT-IN FUNCTION IMPLEMENTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Train sklearn's GaussianNB\n",
        "sklearn_gnb = GaussianNB()\n",
        "sklearn_gnb.fit(X_train, y_train)\n",
        "y_pred_sklearn = sklearn_gnb.predict(X_test)\n",
        "sklearn_accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print(f\"\\n✓ Sklearn Implementation Accuracy: {sklearn_accuracy:.4f} ({sklearn_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_sklearn = confusion_matrix(y_test, y_pred_sklearn)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm_sklearn)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_sklearn, target_names=iris.target_names))\n",
        "\n",
        "# ============================================================================\n",
        "# TASK 2: GridSearchCV for K-NN HYPERPARAMETER TUNING\n",
        "# ============================================================================\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"TASK 2: GRIDSEARCHCV FOR K-NN HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define parameter grid for K values\n",
        "param_grid = {'n_neighbors': list(range(1, 31))}  # Test K from 1 to 30\n",
        "\n",
        "print(f\"\\nParameter Grid: K values from {param_grid['n_neighbors'][0]} to {param_grid['n_neighbors'][-1]}\")\n",
        "\n",
        "# Setup GridSearchCV\n",
        "knn = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=knn,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1  # Use all processors\n",
        ")\n",
        "\n",
        "print(\"\\nPerforming Grid Search with 5-Fold Cross-Validation...\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GRID SEARCH RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n✓ Best K value: {grid_search.best_params_['n_neighbors']}\")\n",
        "print(f\"✓ Best Cross-Validation Accuracy: {grid_search.best_score_:.4f} ({grid_search.best_score_*100:.2f}%)\")\n",
        "\n",
        "# Test on test set\n",
        "best_knn = grid_search.best_estimator_\n",
        "y_pred_knn = best_knn.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"✓ Test Set Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Extract results for display\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Display top 5 K values\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"TOP 5 K VALUES:\")\n",
        "print(\"-\"*70)\n",
        "top_5 = results_df.nlargest(5, 'mean_test_score')[['param_n_neighbors', 'mean_test_score', 'std_test_score']]\n",
        "top_5.columns = ['K', 'Mean CV Accuracy', 'Std Dev']\n",
        "print(top_5.to_string(index=False))\n",
        "\n",
        "# Classification report for best K-NN\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"CLASSIFICATION REPORT (K-NN with K={grid_search.best_params_['n_neighbors']})\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, y_pred_knn, target_names=iris.target_names))\n",
        "\n",
        "# Confusion Matrix for K-NN\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm_knn)\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n1. Gaussian Naïve Bayes:\")\n",
        "print(f\"   - Manual Implementation:  {manual_accuracy*100:.2f}%\")\n",
        "print(f\"   - Sklearn Implementation: {sklearn_accuracy*100:.2f}%\")\n",
        "print(f\"\\n2. K-NN with GridSearchCV:\")\n",
        "print(f\"   - Best K value: {grid_search.best_params_['n_neighbors']}\")\n",
        "print(f\"   - CV Accuracy: {grid_search.best_score_*100:.2f}%\")\n",
        "print(f\"   - Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    }
  ]
}
